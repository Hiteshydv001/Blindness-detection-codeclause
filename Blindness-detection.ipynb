{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:44.513931Z",
     "iopub.status.busy": "2023-09-29T07:02:44.513641Z",
     "iopub.status.idle": "2023-09-29T07:02:44.520396Z",
     "shell.execute_reply": "2023-09-29T07:02:44.519620Z",
     "shell.execute_reply.started": "2023-09-29T07:02:44.513882Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:44.522689Z",
     "iopub.status.busy": "2023-09-29T07:02:44.522169Z",
     "iopub.status.idle": "2023-09-29T07:02:44.540906Z",
     "shell.execute_reply": "2023-09-29T07:02:44.540244Z",
     "shell.execute_reply.started": "2023-09-29T07:02:44.522639Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "train_df['diagnosis'] = train_df['diagnosis'].astype('str')\n",
    "train_df['id_code'] = train_df['id_code'].astype(str)+'.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function \n",
    "* to get image from respective directory(train_images, test_images)\n",
    "* to resize the large image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:44.542894Z",
     "iopub.status.busy": "2023-09-29T07:02:44.542379Z",
     "iopub.status.idle": "2023-09-29T07:02:58.652031Z",
     "shell.execute_reply": "2023-09-29T07:02:58.651198Z",
     "shell.execute_reply.started": "2023-09-29T07:02:44.542841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 validated image filenames belonging to 0 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anacondaInstall\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 3662 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Public\\anacondaInstall\\Lib\\site-packages\\keras\\src\\preprocessing\\image.py:1137: UserWarning: Found 3662 invalid image filename(s) in x_col=\"id_code\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "batch_size = 16\n",
    "image_size = 96\n",
    "\n",
    "\n",
    "\n",
    "train_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(image_size,image_size),\n",
    "    subset='training')\n",
    "\n",
    "test_gen=datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=\"../input/train_images\",\n",
    "    x_col=\"id_code\",\n",
    "    y_col=\"diagnosis\",\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    class_mode=\"categorical\", \n",
    "    target_size=(image_size,image_size),\n",
    "    subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract target column from training data\n",
    "* Convert target column to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.654916Z",
     "iopub.status.busy": "2023-09-29T07:02:58.654376Z",
     "iopub.status.idle": "2023-09-29T07:02:58.660674Z",
     "shell.execute_reply": "2023-09-29T07:02:58.659797Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_train = train_df['diagnosis']\n",
    "# from keras.utils import np_utils\n",
    "# y_train = np_utils.to_categorical(y_train)\n",
    "# num_classes = y_train.shape[1]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical  # Import to_categorical from tf.keras.utils\n",
    "\n",
    "# Load your data and prepare it as needed\n",
    "\n",
    "# Assuming y_train contains your class labels as integers\n",
    "y_train = train_df['diagnosis']\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# Calculate the number of classes\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditional CNN:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.663549Z",
     "iopub.status.busy": "2023-09-29T07:02:58.662888Z",
     "iopub.status.idle": "2023-09-29T07:02:58.670089Z",
     "shell.execute_reply": "2023-09-29T07:02:58.669395Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.663499Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.layers.convolutional'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout, GaussianNoise, GaussianDropout\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Flatten, BatchNormalization\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvolutional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, SeparableConv2D\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstraints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maxnorm\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvolutional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaxPooling2D\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.layers.convolutional'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout, GaussianNoise, GaussianDropout\n",
    "from keras.layers import Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D, SeparableConv2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import regularizers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.672187Z",
     "iopub.status.busy": "2023-09-29T07:02:58.671690Z",
     "iopub.status.idle": "2023-09-29T07:02:58.683819Z",
     "shell.execute_reply": "2023-09-29T07:02:58.683061Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.672123Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Reshape((x_train.shape[0],),))\n",
    "    #model.add(GaussianDropout(0.3,input_shape=[96,96,3]))\n",
    "    model.add(Conv2D(15, (3, 3), input_shape=[96,96,3], activation='relu'))\n",
    "    model.add(GaussianDropout(0.3))\n",
    "    model.add(Conv2D(30, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(50, (5, 5), activation='relu'))\n",
    "    model.add(Conv2D(50, (7, 7), activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n",
    "                   ,activity_regularizer=regularizers.l1(0.01)))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.685784Z",
     "iopub.status.busy": "2023-09-29T07:02:58.685294Z",
     "iopub.status.idle": "2023-09-29T07:02:58.910114Z",
     "shell.execute_reply": "2023-09-29T07:02:58.909398Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.685737Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prevent overfitting,\n",
    "* monitoring the loss on validation/test set for minimum value\n",
    "* run epochs for 20 times when there is no decrease in val_loss\n",
    "* save the best model that has low validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.911506Z",
     "iopub.status.busy": "2023-09-29T07:02:58.911233Z",
     "iopub.status.idle": "2023-09-29T07:02:58.915870Z",
     "shell.execute_reply": "2023-09-29T07:02:58.915116Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.911444Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "es= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\n",
    "mc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T07:02:58.917475Z",
     "iopub.status.busy": "2023-09-29T07:02:58.917022Z",
     "iopub.status.idle": "2023-09-29T07:05:04.897234Z",
     "shell.execute_reply": "2023-09-29T07:05:04.895442Z",
     "shell.execute_reply.started": "2023-09-29T07:02:58.917402Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_gen,              \n",
    "                                    steps_per_epoch=len(train_gen),\n",
    "                                    validation_data=test_gen,                    \n",
    "                                    validation_steps=len(test_gen),\n",
    "                                    epochs=50,\n",
    "                                    callbacks = [es, mc], \n",
    "                                    use_multiprocessing = True,\n",
    "                                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.898867Z",
     "iopub.status.idle": "2023-09-29T07:05:04.899527Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions for given test data and submit the output file in required format (submission.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.900751Z",
     "iopub.status.idle": "2023-09-29T07:05:04.901335Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('../input/sample_submission.csv')\n",
    "#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\n",
    "submission_df['filename'] = submission_df['id_code'].astype(str)+'.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing test images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.902413Z",
     "iopub.status.idle": "2023-09-29T07:05:04.903013Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_datagen=ImageDataGenerator(rescale=1./255)\n",
    "submission_gen=submission_datagen.flow_from_dataframe(\n",
    "    dataframe=submission_df,\n",
    "    directory=\"../input/test_images\",\n",
    "    x_col=\"filename\",    \n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    class_mode=None, \n",
    "    target_size=(image_size,image_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.904083Z",
     "iopub.status.idle": "2023-09-29T07:05:04.904720Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions=model.predict_generator(submission_gen, steps = len(submission_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.905802Z",
     "iopub.status.idle": "2023-09-29T07:05:04.906395Z"
    }
   },
   "outputs": [],
   "source": [
    "max_probability = np.argmax(predictions,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-09-29T07:05:04.907540Z",
     "iopub.status.idle": "2023-09-29T07:05:04.908126Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.drop(columns=['filename'], inplace= True)\n",
    "submission_df['diagnosis'] = max_probability\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
